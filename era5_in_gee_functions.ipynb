{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5 in GEE - Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook lists all functions that are useful to bring ERA5 reanalysis data into Google Earth Engine.\n",
    "\n",
    "The functions can be grouped into the following categories:\n",
    "\n",
    "\n",
    "\n",
    "**[Useful data handling functions](#useful_functions)**\n",
    "* [createFileList](#create_filelist)\n",
    "* [createListOfLists](#create_list_of_lists)\n",
    "* [getEpochTimes](#epoch_times)\n",
    "* [getEpochTimes_daily](#epoch_times_daily)\n",
    "* [getEpochTimes_monthly](#epoch_times_monthly)\n",
    "\n",
    "**[Functions to generate a GeoTiff file with gdal](#generate_geotiff)**\n",
    "* [initTiff](#initTiff)\n",
    "* [createTiff](#create_tiff)\n",
    "* [getScaleFactor](#scale_factor)\n",
    "* [getOffset](#offset)\n",
    "* [setSpatialReference](#spatial_ref)\n",
    "\n",
    "**[Functions to convert NetCDF files to GeoTiffs](#convert_ncs_to_geotiffs)**\n",
    "* [ncToTiff](#nc_tiff)\n",
    "* [ncToTiff_hourly](#nc_tiff_hourly)\n",
    "* [convertFilesToTiff](#convert_to_tiff)\n",
    "\n",
    "**[Functions to temporally aggregate data](#aggregate)**\n",
    "* [createDailyFiles](#aggregate_daily)\n",
    "* [createMonthlyFiles](#aggregate_monthly)\n",
    "\n",
    "**[Functions to create / update manifests](#manifests)**\n",
    "* [updateManifest_hourly](#manifest_hourly)\n",
    "* [updateManifest_daily](#manifest_daily)\n",
    "* [updateManifest_monthly](#manifest_monthly)\n",
    "* [manifestToJSON](#manifest_json)\n",
    "* [createManifestCombined_hourly](#manifest_combined_hourly)\n",
    "* [createManifestCombined_daily](#manifest_combined_daily)\n",
    "* [createManifestCombined_monthly](#manifest_combined_monthly)\n",
    "\n",
    "**[Functions to upload files to Google Cloud Platform](#gcp_upload)**\n",
    "* [upload_blob](#upload_blob)\n",
    "* [uploadMonthlyFileToGCP](#upload_gcp_monthly)\n",
    "* [uploadToGCP](#upload_gcp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import glob\n",
    "from osgeo import gdal, osr\n",
    "import pytz\n",
    "import re\n",
    "import json\n",
    "from google.cloud import storage\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='useful_functions'></a>Useful data handling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='create_filelist'></a>`createFileList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFileList(directory,file_pattern):\n",
    "    os.chdir(directory)\n",
    "    return glob.glob(file_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='create_list_of_lists'></a>`createListOfLists`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createListOfLists(directory_list,aggregation,year):\n",
    "    fileList=[]\n",
    "    for i in directory_list:\n",
    "        os.chdir(i)\n",
    "        fileList_tmp = createFileList(i,'./tiff/'+aggregation+'/'+year+'/*')\n",
    "        fileList_tmp.sort()\n",
    "        fileList.append(fileList_tmp)\n",
    "        os.chdir('..')\n",
    "    return(fileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='epoch_times'></a>`getEpochTimes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEpochTimes(file, noOfBands):\n",
    "    base = datetime(1900,1,1,0,0,0,0).replace(tzinfo=pytz.UTC)\n",
    "    ls_epochtime = []\n",
    "    \n",
    "    for i in range(1,noOfBands+1):\n",
    "        tmp = file.GetRasterBand(i)\n",
    "        tmp_time = tmp.GetMetadata()['NETCDF_DIM_time']\n",
    "        epoch_time = base + timedelta(hours=int(tmp_time))\n",
    "        ls_epochtime.append(int(epoch_time.timestamp()))\n",
    "    epoch_time = base + timedelta(hours=int(tmp_time)+1)\n",
    "    ls_epochtime.append(int(epoch_time.timestamp()))\n",
    "    return ls_epochtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='epoch_times_daily'></a>`getEpochTimes_daily`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEpochTimes_daily(year,month,day):\n",
    "    ls_epochtime = []\n",
    "    startTime = datetime(year,month,day, tzinfo=pytz.utc)\n",
    "    endTime = startTime + timedelta(days=1)\n",
    "    ls_epochtime.append(startTime.timestamp())\n",
    "    ls_epochtime.append(endTime.timestamp())\n",
    "    return ls_epochtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='epoch_times_monthly'></a>`getEpochTimes_monthly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEpochTimes_monthly(year,month):\n",
    "    ls_epochtime = []\n",
    "    startTime = datetime(year,month, 1, tzinfo=pytz.utc)\n",
    "    endTime = startTime + relativedelta(months=+1)\n",
    "    ls_epochtime.append(startTime.timestamp())\n",
    "    ls_epochtime.append(endTime.timestamp())\n",
    "    return ls_epochtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='generate_geotiff'></a>Functions to generate a GeoTiff with `gdal`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='init_tiff'></a>`initTiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initTiff(filename, file, noOfBands):\n",
    "    outFile = gdal.GetDriverByName('GTiff').Create(filename, file.RasterXSize, file.RasterYSize, noOfBands, gdal.GDT_Float32)\n",
    "    geotransform = (-180.0, 0.25, 0.0, 90.0, 0.0, -0.25)\n",
    "    outFile.SetGeoTransform(geotransform)\n",
    "    return outFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='create_tiff'></a>`createTiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTiff(file, outfile, scale_factor, offset):\n",
    "    for j in range(1, file.RasterCount+1):\n",
    "        fileLayer = file.GetRasterBand(j).ReadAsArray().astype('float')\n",
    "        finalArray = float(offset) + (fileLayer * float(scale_factor))\n",
    "        finalArray[finalArray<0] = 0.0\n",
    "        outBand = outfile.GetRasterBand(j)\n",
    "        outBand.WriteArray(finalArray)\n",
    "    return outBand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='scale_factor'></a>`getScaleFactor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScaleFactor(file, parameter):\n",
    "    return float(file.GetMetadataItem(parameter+\"#scale_factor\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='offset'></a>`getOffset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOffset(file, parameter):\n",
    "    return float(file.GetMetadataItem(parameter+\"#add_offset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='spatial_ref'></a>`setSpatialReference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setSpatialReference(file,EPSGCode):\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(EPSGCode)\n",
    "    file.SetProjection(srs.ExportToWkt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='convert_ncs_to_geotiffs'></a>Functions to convert NetCDF files to GeoTiffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='nc_tiff'></a>`ncToTiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncToTiff(file, noOfBands, year,epsgCode,outfile):\n",
    "    outfile = outfile\n",
    "    print(outfile)\n",
    "    ncFile=gdal.Open(file)\n",
    "    outTiff = initTiff(outfile,ncFile,noOfBands)\n",
    "    fileLayer = ncFile.GetRasterBand(1).ReadAsArray().astype('float')\n",
    "    fileLayer[fileLayer<0] = 0.0\n",
    "    outBand = outTiff.GetRasterBand(1)\n",
    "    outBand.WriteArray(fileLayer)\n",
    "    setSpatialReference(outTiff, epsgCode)\n",
    "    outBand.FlushCache()\n",
    "    outTiff=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='nc_tiff_hourly'></a>`ncToTiff_hourly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='convert_to_tiff'></a>`convertFilesToTiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFilesToTiff(directory, time_step, parameter, year, epsg):\n",
    "    fileList = createFileList(directory, './era5_'+parameter+'/nc/'+time_step+'/'+year+'/era5_surface_pressure_1985_06_12*.nc')\n",
    "    print(fileList)\n",
    "    print(len(fileList))\n",
    " #   if(len(fileList)<365):\n",
    " #       return\n",
    "\n",
    "    fileList.sort()\n",
    "    for file in fileList:\n",
    "        tmp = file.split('/')\n",
    "        print(tmp[5][:-3])      \n",
    "        outfile = directory+'era5_'+parameter+'/tiff/'+time_step+'/'+year+'/'+str(tmp[5][:-3])+'.tif'\n",
    "        print(outfile)\n",
    "        if(time_step!='hourly'):\n",
    "            ncToTiff(file,1,year,epsg, outfile)\n",
    "        else:\n",
    "            ncToTiff_hourly(file,24,year, epsg,outfile,parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='aggregate'></a>Functions to temporally aggregate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='aggregate_daily'></a>`createDailyFiles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDailyFiles(directory, parameter, year, aggregation):\n",
    "#    fileList = createFileList(directory, './era5_'+parameter+'/nc/hourly/'+year+'/era5_'+parameter+'_'+year+'*')\n",
    "    fileList = createFileList(directory, './era5_'+parameter+'/nc/hourly/'+year+'/era5_'+parameter+'*')\n",
    "    fileList.sort()\n",
    "    print(fileList)\n",
    "    \n",
    "    for i in range(0,len(fileList)-1):\n",
    "        if(parameter=='tp'):\n",
    "            array=xr.open_mfdataset([fileList[i],fileList[i+1]],concat_dim='time', combine='nested')\n",
    "            print(array)\n",
    "        else:\n",
    "            array = xr.open_dataset(fileList[i], mask_and_scale=True, decode_times=True)\n",
    "            print(array)\n",
    "        tmp = fileList[i].split('/')\n",
    "        print(tmp)\n",
    "\n",
    "        outFileName = directory+'./era5_'+parameter+'/nc/daily/'+year+'/'+tmp[5][:-3]+'_daily_'+aggregation+'.nc'\n",
    "        \n",
    "        print(outFileName)\n",
    "        if(aggregation=='mean'):\n",
    "            print('mean')\n",
    "            array.resample(time='1D').mean().to_netcdf(outFileName, mode='w', compute=True)\n",
    "        elif(aggregation=='sum'):\n",
    "            print('sum')\n",
    "            array.resample(time='1D',closed='right').sum().isel(time=1).to_netcdf(outFileName, mode='w', compute=True)\n",
    "        elif(aggregation=='min'):\n",
    "            print('min')\n",
    "            array.resample(time='1D').min().to_netcdf(outFileName, mode='w', compute=True)\n",
    "        else:\n",
    "            print('max')\n",
    "            array.resample(time='1D').max().to_netcdf(outFileName, mode='w', compute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='aggregate_monthly'></a>`createMonthlyFiles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMonthlyFiles(directory, parameter, year, aggregation):\n",
    "    month_list = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "#    month_list = ['08']\n",
    "    for i in month_list:\n",
    "        fileList_param = createFileList(directory,'./era5_'+parameter+'/nc/'+year+'/era5_'+parameter+'_'+year+'_'+i+'*')\n",
    "        fileList_param.sort()\n",
    "        print(fileList_param)\n",
    "        os.chdir(directory)\n",
    "        array_param = xr.open_mfdataset(fileList_param,combine='nested', concat_dim='time')\n",
    "        print(array_param)\n",
    "        tmp = fileList_param[0].split('/')\n",
    "        outFileName_param = directory+'./era5_'+parameter+'/nc/monthly/'+year+'/'+tmp[4][:-6]+'_monthly_'+aggregation+'.nc'\n",
    "        if(aggregation=='mean'):\n",
    "            print('mean')\n",
    "            array_param.resample(time='1M').mean().to_netcdf(outFileName_param, mode='w', compute=True)\n",
    "        elif(aggregation=='sum'):\n",
    "            print('sum')\n",
    "            array_param.resample(time='1M').sum().to_netcdf(outFileName_param, mode='w', compute=True)\n",
    "        elif(aggregation=='min'):\n",
    "            print('min')\n",
    "            array_param.resample(time='1M').min().to_netcdf(outFileName_param, mode='w', compute=True)\n",
    "        else:\n",
    "            print('max')\n",
    "            array_param.resample(time='1M').max().to_netcdf(outFileName_param, mode='w', compute=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='manifests'></a>Functions to create / update manifests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='manifest_hourly'></a>`updateManifest_hourly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateManifest_hourly(directory, eeCollectionName, assetName, startTime, endTime, bandIndex, gs_bucket_list, uris1, uris2, uris3, uris4, uris5, uris6, uris7, uris8, uris9, year,month, day, hour):\n",
    "    with open(directory+'manifest_structure_hourly.json','r') as f:\n",
    "        jsonFile = json.load(f)\n",
    "\n",
    "    jsonFile['name']=eeCollectionName+assetName\n",
    "    jsonFile['tilesets'][0]['sources'][0]['uris']='gs://'+gs_bucket_list[0]+'/'+uris1\n",
    "    jsonFile['tilesets'][1]['sources'][0]['uris']='gs://'+gs_bucket_list[1]+'/'+uris2\n",
    "    jsonFile['tilesets'][2]['sources'][0]['uris']='gs://'+gs_bucket_list[2]+'/'+uris3\n",
    "    jsonFile['tilesets'][3]['sources'][0]['uris']='gs://'+gs_bucket_list[3]+'/'+uris4\n",
    "    jsonFile['tilesets'][4]['sources'][0]['uris']='gs://'+gs_bucket_list[4]+'/'+uris5\n",
    "    jsonFile['tilesets'][5]['sources'][0]['uris']='gs://'+gs_bucket_list[5]+'/'+uris6\n",
    "    jsonFile['tilesets'][6]['sources'][0]['uris']='gs://'+gs_bucket_list[6]+'/'+uris7\n",
    "    jsonFile['tilesets'][7]['sources'][0]['uris']='gs://'+gs_bucket_list[7]+'/'+uris8\n",
    "    jsonFile['tilesets'][8]['sources'][0]['uris']='gs://'+gs_bucket_list[8]+'/'+uris9\n",
    "\n",
    "    jsonFile['bands'][0]['tileset_band_index']=bandIndex\n",
    "    jsonFile['bands'][1]['tileset_band_index']=bandIndex\n",
    "    jsonFile['bands'][2]['tileset_band_index']=bandIndex\n",
    "    jsonFile['bands'][3]['tileset_band_index']=bandIndex\n",
    "    jsonFile['bands'][4]['tileset_band_index']=bandIndex\n",
    "    jsonFile['bands'][5]['tileset_band_index']=bandIndex\n",
    "    jsonFile['bands'][6]['tileset_band_index']=bandIndex\n",
    "    jsonFile['bands'][7]['tileset_band_index']=bandIndex\n",
    "    jsonFile['bands'][8]['tileset_band_index']=bandIndex\n",
    "\n",
    "    jsonFile['start_time']['seconds']=startTime\n",
    "    jsonFile['end_time']['seconds']=endTime\n",
    "    jsonFile['properties']['year']=year\n",
    "    jsonFile['properties']['month']=month\n",
    "    jsonFile['properties']['day']=day \n",
    "    jsonFile['properties']['hour']=hour\n",
    "    return jsonFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='manifest_daily'></a>`updateManifest_daily`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateManifest_daily(directory, eeCollectionName, assetName, startTime, endTime, gs_bucket_list, uris1, uris2, uris3, uris4, uris5, uris6, uris7, uris8, year,month, day):\n",
    "    with open(directory+'manifest_structure_daily.json','r') as f:\n",
    "        jsonFile = json.load(f)\n",
    "\n",
    "    jsonFile['name']=eeCollectionName+assetName\n",
    "    jsonFile['tilesets'][0]['sources'][0]['uris']='gs://'+gs_bucket_list[0]+'/'+uris1\n",
    "    jsonFile['tilesets'][1]['sources'][0]['uris']='gs://'+gs_bucket_list[1]+'/'+uris2\n",
    "    jsonFile['tilesets'][2]['sources'][0]['uris']='gs://'+gs_bucket_list[2]+'/'+uris3\n",
    "    jsonFile['tilesets'][3]['sources'][0]['uris']='gs://'+gs_bucket_list[3]+'/'+uris4\n",
    "    jsonFile['tilesets'][4]['sources'][0]['uris']='gs://era5_tp_daily/era5_tp_'+str(year)+'_'+str(month).zfill(2)+'_'+str(day).zfill(2)+'_daily_sum.tif'\n",
    "    jsonFile['tilesets'][5]['sources'][0]['uris']='gs://'+gs_bucket_list[4]+'/'+uris5\n",
    "    jsonFile['tilesets'][6]['sources'][0]['uris']='gs://'+gs_bucket_list[5]+'/'+uris6\n",
    "    jsonFile['tilesets'][7]['sources'][0]['uris']='gs://'+gs_bucket_list[6]+'/'+uris7\n",
    "    jsonFile['tilesets'][8]['sources'][0]['uris']='gs://'+gs_bucket_list[7]+'/'+uris8\n",
    " #   jsonFile['tilesets'][8]['sources'][0]['uris']=gs_bucket_list[8]+uris9    \n",
    "    jsonFile['start_time']['seconds']=startTime\n",
    "    jsonFile['end_time']['seconds']=endTime\n",
    "    jsonFile['properties']['year']=year\n",
    "    jsonFile['properties']['month']=month\n",
    "    jsonFile['properties']['day']=day   \n",
    "    return jsonFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='manifest_monthly'></a>`updateManifest_monthly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateManifest_monthly(directory,eeCollectionName, assetName, startTime, endTime, gs_bucket_list, uris1, uris2, uris3, uris4, uris5, uris6, uris7, uris8, year, month):\n",
    "    with open(directory+'manifest_structure_monthly.json','r') as f:\n",
    "        jsonFile = json.load(f)\n",
    "\n",
    "    jsonFile['name']=eeCollectionName+assetName\n",
    "    jsonFile['tilesets'][0]['sources'][0]['uris']='gs://'+gs_bucket_list[0]+'/'+uris1\n",
    "    jsonFile['tilesets'][1]['sources'][0]['uris']='gs://'+gs_bucket_list[1]+'/'+uris2\n",
    "    jsonFile['tilesets'][2]['sources'][0]['uris']='gs://'+gs_bucket_list[2]+'/'+uris3\n",
    "    jsonFile['tilesets'][3]['sources'][0]['uris']='gs://'+gs_bucket_list[3]+'/'+uris4\n",
    "    jsonFile['tilesets'][4]['sources'][0]['uris']='gs://era5_tp_monthly/era5_tp_'+str(year)+'_'+str(month).zfill(2)+'_monthly_sum.tif'\n",
    "    jsonFile['tilesets'][5]['sources'][0]['uris']='gs://'+gs_bucket_list[4]+'/'+uris5\n",
    "    jsonFile['tilesets'][6]['sources'][0]['uris']='gs://'+gs_bucket_list[5]+'/'+uris6\n",
    "    jsonFile['tilesets'][7]['sources'][0]['uris']='gs://'+gs_bucket_list[6]+'/'+uris7\n",
    "    jsonFile['tilesets'][8]['sources'][0]['uris']='gs://'+gs_bucket_list[7]+'/'+uris8\n",
    "    jsonFile['start_time']['seconds']=startTime\n",
    "    jsonFile['end_time']['seconds']=endTime\n",
    "    jsonFile['properties']['year']=year\n",
    "    jsonFile['properties']['month']=month\n",
    "    return jsonFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='manifest_json'></a>`manifestToJSON`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manifestToJSON(manifestDict, path,outFile):\n",
    "    with open(path+outFile+'.json','w') as fp:\n",
    "        json.dump(manifestDict,fp,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='manifest_combined_hourly'></a>`createManifestCombined_hourly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef createManifestCombined_hourly(fileList, ncFileList, year, bucket_list, directory_manifest,directory_outfile):\n",
    "    print\n",
    "    for i in range(0,len(fileList[0])):\n",
    "        print(len(fileList[0]))\n",
    "        item = list(zip(*fileList))[i]\n",
    "        print('item', item)\n",
    "        tmp = re.findall('\\d+', item[0])\n",
    "        print(tmp)\n",
    "        assetName=tmp[3]+tmp[4]+tmp[5]\n",
    "        print('assetname', assetName)\n",
    "        print(item[0])\n",
    "        ncFile = gdal.Open(ncFileList[i])\n",
    "\n",
    "        ls_epochtimes = getEpochTimes(ncFile,24)\n",
    "        print(ls_epochtimes)\n",
    "        uris_list = []\n",
    "        for i in item:\n",
    "             tmp2 = i.split('/')\n",
    "             uris_list.append(tmp2[4])\n",
    "        print(uris_list)\n",
    "\n",
    "        for k in range(0,len(ls_epochtimes)-1):\n",
    "            print(k)\n",
    "            hour= str(k).zfill(2)\n",
    "            manifest = updateManifest_hourly(directory=directory_manifest,\n",
    "                                  eeCollectionName='projects/earthengine-legacy/assets/projects/ecmwf/era5_hourly/',\n",
    "                                  assetName=assetName+'T'+hour,\n",
    "                                  startTime=int(ls_epochtimes[k]),\n",
    "                                  endTime=int(ls_epochtimes[k+1]),\n",
    "                                  bandIndex=k,\n",
    "                                  gs_bucket_list=bucket_list,\n",
    "                                  uris1=uris_list[0],\n",
    "                                  uris2=uris_list[1],\n",
    "                                  uris3=uris_list[2],\n",
    "                                  uris4=uris_list[3],\n",
    "                                  uris5=uris_list[4],\n",
    "                                  uris6=uris_list[5],\n",
    "                                  uris7=uris_list[6],\n",
    "                                  uris8=uris_list[7],\n",
    "                                  uris9=uris_list[8],\n",
    "                                  year=int(tmp[3]),\n",
    "                                  month=int(tmp[4]),\n",
    "                                  day=int(tmp[5]),\n",
    "                                  hour=int(hour))\n",
    "            outfile='manifest_'+assetName+hour+'_hourly'\n",
    "            manifestToJSON(manifest,directory_outfile+year+'/',outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='manifest_combined_daily'></a>`createManifestCombined_daily`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createManifestCombined_daily(fileList, year,bucket_list, directory_manifest,directory_outfile):\n",
    "    item = list(zip(*fileList))[0]\n",
    "    print(item)\n",
    "    for i in range(0,len(fileList[0])):\n",
    "#        print(i)\n",
    "        item = list(zip(*fileList))[i]\n",
    "#        print(item)\n",
    "        tmp = re.findall('\\d+', item[0])\n",
    "        assetName=tmp[3]+tmp[4]+tmp[5]\n",
    "        ls_epochtimes = getEpochTimes_daily(int(tmp[3]),int(tmp[4]),int(tmp[5]))\n",
    "        uris_list = []\n",
    "        for i in item:\n",
    "            tmp2 = i.split('/')\n",
    "            uris_list.append(tmp2[4])\n",
    "        manifest = updateManifest_daily(directory=directory_manifest,\n",
    "                                        eeCollectionName='projects/earthengine-legacy/assets/projects/ecmwf/era5_daily/',\n",
    "                                        assetName=assetName,\n",
    "                                        startTime = int(ls_epochtimes[0]),\n",
    "                                        endTime = int(ls_epochtimes[1]),\n",
    "                                        gs_bucket_list = bucket_list,\n",
    "                                        uris1=uris_list[0],\n",
    "                                        uris2=uris_list[1],\n",
    "                                        uris3=uris_list[2],\n",
    "                                        uris4=uris_list[3],\n",
    "                                        uris5=uris_list[4],\n",
    "                                        uris6=uris_list[5],\n",
    "                                        uris7=uris_list[6],\n",
    "                                        uris8=uris_list[7],\n",
    "                                        year=int(tmp[3]),\n",
    "                                        month=int(tmp[4]),\n",
    "                                        day=int(tmp[5]))\n",
    "        outfile='manifest_'+assetName+'_daily'\n",
    "        manifestToJSON(manifest,directory_outfile+year+'/',outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='manifest_combined_monthly'></a>`createManifestCombined_monthly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createManifestCombined_monthly(fileList, year,bucket_list, directory_manifest,directory_outfile):\n",
    "    item = list(zip(*fileList))[0]\n",
    "    print(item)\n",
    "    for i in range(0,len(fileList[0])):\n",
    "#        print(i)\n",
    "        item = list(zip(*fileList))[i]\n",
    "#        print(item)\n",
    "        tmp = re.findall('\\d+', item[0])\n",
    "        assetName=tmp[3]+tmp[4]\n",
    "        ls_epochtimes = getEpochTimes_monthly(int(tmp[3]),int(tmp[4]))\n",
    "        uris_list = []\n",
    "        for i in item:\n",
    "            tmp2 = i.split('/')\n",
    "            print(tmp2)\n",
    "            uris_list.append(tmp2[4])\n",
    "        manifest = updateManifest_monthly(directory=directory_manifest,\n",
    "                                        eeCollectionName='projects/earthengine-legacy/assets/projects/ecmwf/era5_monthly/',\n",
    "                                        assetName=assetName,\n",
    "                                        startTime = int(ls_epochtimes[0]),\n",
    "                                        endTime = int(ls_epochtimes[1]),\n",
    "                                        gs_bucket_list = bucket_list,\n",
    "                                        uris1=uris_list[0],\n",
    "                                        uris2=uris_list[1],\n",
    "                                        uris3=uris_list[2],\n",
    "                                        uris4=uris_list[3],\n",
    "                                        uris5=uris_list[4],\n",
    "                                        uris6=uris_list[5],\n",
    "                                        uris7=uris_list[6],\n",
    "                                        uris8=uris_list[7],\n",
    "                                        year=int(tmp[3]),\n",
    "                                        month=int(tmp[4]))\n",
    "        outfile='manifest_'+assetName+'_monthly'\n",
    "        manifestToJSON(manifest,directory_outfile+year+'/',outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='gcp_upload'></a>Functions to upload files to Google Cloud Platform (GCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='upload_blob'></a>`upload_blob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    if(blob.exists()):\n",
    "        print('File {} already exists'.format(destination_blob_name))\n",
    "        next\n",
    "    else:\n",
    "        blob.upload_from_filename(source_file_name)\n",
    "\n",
    "        print('File {} uploaded to {}.'.format(\n",
    "                source_file_name,\n",
    "                destination_blob_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='upload_gcp_monthly'></a>`uploadMonthlyFilesToGCP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadMonthlyFilesToGCP(directory,parameter,year,bucket):\n",
    "    fileList = createFileList(directory,'./era5_'+parameter+'/tiff/monthly/'+year+'/*08_monthly*')\n",
    "    fileList.sort()\n",
    "    for file in fileList:\n",
    "        tmp = file.split('/')\n",
    "        print(tmp)\n",
    "        destname = tmp[5]\n",
    "        print(destname)\n",
    "        upload_blob(bucket,file,destname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='upload_gcp'></a>`uploadToGCP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadToGCP(directory,year,time_step,parameter,bucket):\n",
    "    fileList = createFileList(directory, 'era5_'+parameter+'/tiff/'+time_step+'/'+year+'/*.tif')\n",
    "    fileList.sort()\n",
    "\n",
    "    for file in fileList:\n",
    "        print(file)\n",
    "        tmp = file.split('/')\n",
    "        print(tmp)\n",
    "\n",
    "        upload_blob(bucket,file,tmp[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" align='right' /></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
